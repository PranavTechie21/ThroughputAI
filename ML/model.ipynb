import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

try:
    from ortools.sat.python import cp_model
    ortools_available = True
except ImportError:
    ortools_available = False

df = pd.read_csv(r"train_level_dataset (1).csv")
priority_map = {"Low": 1, "Medium": 2, "High": 3}
df["Priority"] = df["Priority"].map(priority_map)

def time_to_minutes(t):
    h, m = map(int, t.split(":"))
    return h * 60 + m

df["Scheduled_Arrival"] = df["Scheduled_Arrival"].apply(time_to_minutes)
df["Scheduled_Departure"] = df["Scheduled_Departure"].apply(time_to_minutes)
df["Conflict_Flag"] = df["Conflict_Flag"].astype(int)

features = ["Train_Type", "Section_ID", "Priority",
            "Scheduled_Arrival", "Scheduled_Departure",
            "Platform_Avail", "Signal_Status", "Track_Capacity", "Hour"]

target_delay = "Delay_Mins"
target_conflict = "Conflict_Flag"
target_throughput = "Throughput_Target"

X = df[features]
y = df[[target_delay, target_conflict, target_throughput]]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

categorical = ["Train_Type", "Section_ID", "Signal_Status"]
numerical = ["Priority", "Scheduled_Arrival", "Scheduled_Departure", "Track_Capacity", "Hour"]
binary = ["Platform_Avail"]

preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical),
        ("num", StandardScaler(), numerical),
        ("bin", "passthrough", binary)
    ]
)

X_train_proc = preprocessor.fit_transform(X_train)
X_val_proc = preprocessor.transform(X_val)

inputs = Input(shape=(X_train_proc.shape[1],), name="input")

shared = Dense(128)(inputs)
shared = LeakyReLU()(shared)
shared = BatchNormalization()(shared)
shared = Dropout(0.3)(shared)

shared = Dense(64)(shared)
shared = LeakyReLU()(shared)
shared = BatchNormalization()(shared)

delay_tower = Dense(64)(shared)
delay_tower = LeakyReLU()(delay_tower)
delay_tower = Dropout(0.2)(delay_tower)
delay_output = Dense(1, name="delay")(delay_tower)

conflict_tower = Dense(32)(shared)
conflict_tower = LeakyReLU()(conflict_tower)
conflict_tower = Dropout(0.2)(conflict_tower)
conflict_output = Dense(1, activation="sigmoid", name="conflict")(conflict_tower)

throughput_tower = Dense(32)(shared)
throughput_tower = LeakyReLU()(throughput_tower)
throughput_output = Dense(1, name="throughput")(throughput_tower)

model = Model(inputs=inputs, outputs=[delay_output, conflict_output, throughput_output])

losses = {
    "delay": "mse",
    "conflict": "binary_crossentropy",
    "throughput": "mse"
}
loss_weights = {
    "delay": 0.5,
    "conflict": 1.0,
    "throughput": 1.5
}

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss=losses,
    loss_weights=loss_weights,
    metrics={
        "delay": ["mae"],
        "conflict": ["accuracy"],
        "throughput": ["mae"]
    }
)

callbacks = [
    EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=5)
]

history = model.fit(
    X_train_proc,
    {"delay": y_train[target_delay],
     "conflict": y_train[target_conflict],
     "throughput": y_train[target_throughput]},
    validation_data=(X_val_proc, {
        "delay": y_val[target_delay],
        "conflict": y_val[target_conflict],
        "throughput": y_val[target_throughput]
    }),
    epochs=80,
    batch_size=64,
    callbacks=callbacks,
    verbose=1
)

final_train = model.evaluate(X_train_proc, 
    {"delay": y_train[target_delay],
     "conflict": y_train[target_conflict],
     "throughput": y_train[target_throughput]}, 
    verbose=0, return_dict=True)

final_val = model.evaluate(X_val_proc, 
    {"delay": y_val[target_delay],
     "conflict": y_val[target_conflict],
     "throughput": y_val[target_throughput]}, 
    verbose=0, return_dict=True)

sample_input = pd.DataFrame([{
    "Train_Type": "Express",
    "Section_ID": "SEC_12",
    "Priority": 3,
    "Scheduled_Arrival": 545,
    "Scheduled_Departure": 547,
    "Platform_Avail": 1,
    "Signal_Status": "Green",
    "Track_Capacity": 4,
    "Hour": 9
}])

sample_proc = preprocessor.transform(sample_input)
pred_delay, pred_conflict, pred_throughput = model.predict(sample_proc)

if ortools_available:

    def run_train_scheduler(trains, pred_delays, pred_throughputs, num_platforms_per_station):
        cp = cp_model.CpModel()
        start_vars, platform_vars = {}, {}
        train_duration = 2

        for train in trains:
            tid = train["train_id"]
            min_start = max(train["scheduled_arrival"],
                            train["scheduled_arrival"] + int(pred_delays[tid] - 5))
            max_start = train["scheduled_arrival"] + int(pred_delays[tid] + 5)

            start_vars[tid] = cp.NewIntVar(min_start, max_start, f"start_{tid}")
            platform_vars[tid] = cp.NewIntVar(1, num_platforms_per_station[train["station_id"]],
                                              f"platform_{tid}")

        objective_terms = []
        for train in trains:
            tid = train["train_id"]
            delay = start_vars[tid] - train["scheduled_arrival"]
            delay_weight = train["priority"]
            throughput_reward = int(pred_throughputs[tid])
            objective_terms.append(delay * delay_weight - throughput_reward)

        cp.Minimize(sum(objective_terms))

        solver = cp_model.CpSolver()
        solver.parameters.max_time_in_seconds = 2.0
        status = solver.Solve(cp)

        schedule = {}
        if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
            for train in trains:
                tid = train["train_id"]
                schedule[tid] = {
                    "optimized_start": solver.Value(start_vars[tid]),
                    "platform": solver.Value(platform_vars[tid])
                }
        return schedule

    def generate_ai_recommendations(trains, optimized_schedule):
        recs = []
        for t in trains:
            tid = t["train_id"]
            if tid in optimized_schedule:
                opt = optimized_schedule[tid]
                recs.append(f"Train {tid}: Start {t['scheduled_arrival']} â†’ {opt['optimized_start']} "
                            f"(Platform {opt['platform']})")
        return recs

    train_id = 101
    sample_trains = [{
        "train_id": train_id,
        "scheduled_arrival": sample_input["Scheduled_Arrival"][0],
        "scheduled_departure": sample_input["Scheduled_Departure"][0],
        "priority": sample_input["Priority"][0],
        "section_id": sample_input["Section_ID"][0],
        "station_id": 1,
        "platform_id": 1
    }]

    pred_delays = {train_id: pred_delay[0][0]}
    pred_throughputs = {train_id: pred_throughput[0][0]}
    num_platforms_per_station = {1: 2}

    optimized_schedule = run_train_scheduler(sample_trains, pred_delays, pred_throughputs, num_platforms_per_station)
    ai_recs = generate_ai_recommendations(sample_trains, optimized_schedule)